services:
  db:
    hostname: db
    image: postgres:15.3-alpine
    container_name: nlp-db
    command: postgres -c idle_session_timeout=600000 -c max_connections=300
    restart: always
    env_file: .env
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U akcent -d nlp"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - postgres_data:/var/lib/postgresql/data/

  redis:
    image: redis:7.0.11-alpine
    restart: always
    volumes:
      - redis-data:/var/lib/redis
    command: redis-server --requirepass ${REDIS_PASSWORD}

  nginx:
    image: nlp/nginx:latest
    restart: always
    depends_on:
      - django
    ports:
      - "8000:443"
    volumes:
      - ${WORKDIR_PATH}/ssl:/usr/src/app/ssl
      - ${WORKDIR_PATH}/public/static:/usr/src/app/public/static
      - ${WORKDIR_PATH}/public/media:/usr/src/app/public/media
    environment:
      NGINX_HOSTNAME: ${NGINX_HOSTNAME}
    command: /bin/sh -c "./etc/nginx/conf.d/config.sh && exec nginx -g 'daemon off;'"

  django:
    image: nlp/django:latest
    command: bash -c "./initapp.sh"
    container_name: 'nlp-django'
    restart: unless-stopped
    depends_on:
      - db
      - redis
    expose:
      - 8000
    env_file: .env
    volumes:
      - ${WORKDIR_PATH}/public/static:/usr/src/app/public/static
      - ${WORKDIR_PATH}/public/media:/usr/src/app/public/media
      - ${WORKDIR_PATH}/private:/usr/src/app/private
      - ${WORKDIR_PATH}/llm:/usr/src/app/models

  worker-default:
    image: nlp/django:latest
    command: bash -c "celery -A nlp worker -Q default --loglevel=info -E --autoscale=4,2 --purge"
    container_name: 'worker-default'
    restart: unless-stopped
    depends_on:
      - django
      - redis
    env_file: .env
    volumes:
      - ${WORKDIR_PATH}/public/static:/usr/src/app/public/static
      - ${WORKDIR_PATH}/public/media:/usr/src/app/public/media
      - ${WORKDIR_PATH}/private:/usr/src/app/private
      - ${WORKDIR_PATH}/llm:/usr/src/app/models

  worker-low:
    image: nlp/django:latest
    command: bash -c "celery -A nlp worker -Q low --loglevel=info -E --autoscale=4,2 --purge"
    container_name: 'worker-low'
    restart: unless-stopped
    depends_on:
      - django
      - redis
    env_file: .env
    volumes:
      - ${WORKDIR_PATH}/public/static:/usr/src/app/public/static
      - ${WORKDIR_PATH}/public/media:/usr/src/app/public/media
      - ${WORKDIR_PATH}/private:/usr/src/app/private
      - ${WORKDIR_PATH}/llm:/usr/src/app/models

  worker-high:
    image: nlp/django:latest
    command: bash -c "celery -A nlp worker -Q high --loglevel=info -E --autoscale=4,2 --purge"
    container_name: 'worker-high'
    restart: unless-stopped
    depends_on:
      - django
      - redis
    env_file: .env
    volumes:
      - ${WORKDIR_PATH}/public/static:/usr/src/app/public/static
      - ${WORKDIR_PATH}/public/media:/usr/src/app/public/media
      - ${WORKDIR_PATH}/private:/usr/src/app/private
      - ${WORKDIR_PATH}/llm:/usr/src/app/models

  scheduler:
    image: nlp/django:latest
    command: bash -c "celery -A nlp beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler"
    container_name: 'nlp-celery-beat'
    restart: unless-stopped
    depends_on:
      - django
      - redis
    env_file: .env
    volumes:
      - ${WORKDIR_PATH}/public/static:/usr/src/app/public/static
      - ${WORKDIR_PATH}/public/media:/usr/src/app/public/media

  llm_service:
    image: nlp/llm:latest
    command: bash -c "./models/init_llm.sh"
    container_name: 'llm-service'
    restart: unless-stopped
    depends_on:
      - db
      - redis
    expose:
      - 8001
      - 8002
    env_file: .env
    volumes:
      - ${WORKDIR_PATH}/llm:/usr/src/app/models  # Директория с моделями
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu


volumes:
  postgres_data:
  redis-data:
